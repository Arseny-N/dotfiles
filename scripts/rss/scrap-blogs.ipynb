{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  !pip install git+git://github.com/svpino/rfeed#egg=rfeed\n",
    "#  !pip install dateparser\n",
    "!pip install favicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import dateparser\n",
    "from rfeed import *\n",
    "from urllib.parse import urlparse, urljoin\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import favicon\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrap_target = os.environ.get('SCRAP_TARGET')\n",
    "fetch_from_web = bool(os.environ.get('FETCH_FROM_WEB'))\n",
    "\n",
    "registry[scrap_target](fetch_from_web=fetch_from_web).html_to_feed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/lagrangian-nns/thumbnail.png\" style=\"width:65%; height:65%\">\n",
       " </img></div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Mar 10, 2020</span>\n",
       " <a class=\"post-link\" href=\"/2020/03/10/lagrangian-nns/\">Lagrangian Neural Networks</a>\n",
       " <br/>\n",
       "         As a complement to Hamiltonian Neural Networks, I discuss how to parameterize Lagrangians with neural networks and then learn them from data.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/lagrangian-nns/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Mar 10, 2020</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2020/03/10/lagrangian-nns/\">Lagrangian Neural Networks</a>\n",
       "         <br>\n",
       "         As a complement to Hamiltonian Neural Networks, I discuss how to parameterize Lagrangians with neural networks and then learn them from data. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/paths-perspective/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Jan 27, 2020</span>\n",
       " <a class=\"post-link\" href=\"/2020/01/27/paths-perspective/\">Distill Article: The Paths Perspective on Value Learning</a>\n",
       " <br/>\n",
       "         I recently published a Distill article about value learning. This post includes a link to the article and some meta-commentary about the Distill format.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/paths-perspective/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Jan 27, 2020</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2020/01/27/paths-perspective/\">Distill Article: The Paths Perspective on Value Learning</a>\n",
       "         <br>\n",
       "         I recently published a Distill article about value learning. This post includes a link to the article and some meta-commentary about the Distill format. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/neural-reparam/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Dec 15, 2019</span>\n",
       " <a class=\"post-link\" href=\"/2019/12/15/neural-reparam/\">Neural Reparameterization Improves Structural Optimization</a>\n",
       " <br/>\n",
       "         We propose using neural networks to reparameterize physics problems. This helps us design better bridges, skyscrapers, and cantilevers while enforcing hard physical constraints.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/neural-reparam/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Dec 15, 2019</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2019/12/15/neural-reparam/\">Neural Reparameterization Improves Structural Optimization</a>\n",
       "         <br>\n",
       "         We propose using neural networks to reparameterize physics problems. This helps us design better bridges, skyscrapers, and cantilevers while enforcing hard physical constraints. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/hamiltonian-nns/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">May 15, 2019</span>\n",
       " <a class=\"post-link\" href=\"/2019/05/15/hamiltonian-nns/\">Hamiltonian Neural Networks</a>\n",
       " <br/>\n",
       "         Instead of crafting Hamiltonians by hand, we propose parameterizing them with neural networks and then learning them directly from data.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/hamiltonian-nns/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">May 15, 2019</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2019/05/15/hamiltonian-nns/\">Hamiltonian Neural Networks</a>\n",
       "         <br>\n",
       "         Instead of crafting Hamiltonians by hand, we propose parameterizing them with neural networks and then learning them directly from data. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/neurips17/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Dec 23, 2017</span>\n",
       " <a class=\"post-link\" href=\"/2017/12/23/neurips17/\">A Review of NeurIPS 2017</a>\n",
       " <br/>\n",
       "         Billion dollar investments. Top-tier scientists. Flo Rida. NeurIPS 2017 was a confusing, absurd, and inspirational roller coaster ride. Let's try to understand what happened.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/neurips17/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Dec 23, 2017</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2017/12/23/neurips17/\">A Review of NeurIPS 2017</a>\n",
       "         <br>\n",
       "         Billion dollar investments. Top-tier scientists. Flo Rida. NeurIPS 2017 was a confusing, absurd, and inspirational roller coaster ride. Let's try to understand what happened. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/visualize-atari/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Nov 1, 2017</span>\n",
       " <a class=\"post-link\" href=\"/2017/11/01/visualize-atari/\">Visualizing and Understanding Atari Agents</a>\n",
       " <br/>\n",
       "         Deep RL agents are effective at maximizing rewards but it's often unclear what strategies they use to do so. I'll talk about a paper I just finished, aimed at solving this problem.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/visualize-atari/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Nov 1, 2017</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2017/11/01/visualize-atari/\">Visualizing and Understanding Atari Agents</a>\n",
       "         <br>\n",
       "         Deep RL agents are effective at maximizing rewards but it's often unclear what strategies they use to do so. I'll talk about a paper I just finished, aimed at solving this problem. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/subspace-nn/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Oct 30, 2017</span>\n",
       " <a class=\"post-link\" href=\"/2017/10/30/subspace-nn/\">Training Networks in Random Subspaces</a>\n",
       " <br/>\n",
       "         Do we really need over 100,000 free parameters to build a good MNIST classifier? It turns out that we can eliminate 80-90% of them.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/subspace-nn/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Oct 30, 2017</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2017/10/30/subspace-nn/\">Training Networks in Random Subspaces</a>\n",
       "         <br>\n",
       "         Do we really need over 100,000 free parameters to build a good MNIST classifier? It turns out that we can eliminate 80-90% of them. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/quantum-nn/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Jul 28, 2017</span>\n",
       " <a class=\"post-link\" href=\"/2017/07/28/quantum-nn/\">Taming Wave Functions with Neural Networks</a>\n",
       " <br/>\n",
       "         The wave function is essential to most calculations in quantum mechanics, and yet it's a difficult beast to tame. Can neural networks help?\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/quantum-nn/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Jul 28, 2017</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2017/07/28/quantum-nn/\">Taming Wave Functions with Neural Networks</a>\n",
       "         <br>\n",
       "         The wave function is essential to most calculations in quantum mechanics, and yet it's a difficult beast to tame. Can neural networks help? -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/dnc/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Feb 27, 2017</span>\n",
       " <a class=\"post-link\" href=\"/2017/02/27/differentiable-memory-and-the-brain/\">Differentiable Memory and the Brain</a>\n",
       " <br/>\n",
       "         DeepMind's Differentiable Neural Computer (DNC) represents the state of the art in differentiable memory models. I introduce an analogy between the DNC and human memory, then discuss where it breaks down.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/dnc/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Feb 27, 2017</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2017/02/27/differentiable-memory-and-the-brain/\">Differentiable Memory and the Brain</a>\n",
       "         <br>\n",
       "         DeepMind's Differentiable Neural Computer (DNC) represents the state of the art in differentiable memory models. I introduce an analogy between the DNC and human memory, then discuss where it breaks down. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/enigma-rnn/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Jan 7, 2017</span>\n",
       " <a class=\"post-link\" href=\"/2017/01/07/enigma-rnn/\">Learning the Enigma with Recurrent Neural Networks</a>\n",
       " <br/>\n",
       "         Recurrent Neural Networks (RNNs) are Turing-complete. In other words, they can approximate any function. As a tip of the hat to Alan Turing, let's see if we can use them to learn the Enigma cipher.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/enigma-rnn/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Jan 7, 2017</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2017/01/07/enigma-rnn/\">Learning the Enigma with Recurrent Neural Networks</a>\n",
       "         <br>\n",
       "         Recurrent Neural Networks (RNNs) are Turing-complete. In other words, they can approximate any function. As a tip of the hat to Alan Turing, let's see if we can use them to learn the Enigma cipher. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/synthetic-gradients/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Nov 26, 2016</span>\n",
       " <a class=\"post-link\" href=\"/2016/11/26/synthetic-gradients/\">A Bird's Eye View of Synthetic Gradients</a>\n",
       " <br/>\n",
       "         Synthetic gradients achieve the perfect balance of crazy and brilliant. In a 100-line Gist I'll introduce this exotic technique and use it to train a neural network.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/synthetic-gradients/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Nov 26, 2016</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2016/11/26/synthetic-gradients/\">A Bird's Eye View of Synthetic Gradients</a>\n",
       "         <br>\n",
       "         Synthetic gradients achieve the perfect balance of crazy and brilliant. In a 100-line Gist I'll introduce this exotic technique and use it to train a neural network. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/regularization/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Sep 5, 2016</span>\n",
       " <a class=\"post-link\" href=\"/2016/09/05/regularization/\">The Art of Regularization</a>\n",
       " <br/>\n",
       "         Regularization seems fairly insignificant at first glance, but it has a huge impact on deep models. I'll use a one-layer neural network trained on the MNIST dataset to give an intuition for how common regularization techniques affect learning.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/regularization/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Sep 5, 2016</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2016/09/05/regularization/\">The Art of Regularization</a>\n",
       "         <br>\n",
       "         Regularization seems fairly insignificant at first glance, but it has a huge impact on deep models. I'll use a one-layer neural network trained on the MNIST dataset to give an intuition for how common regularization techniques affect learning. -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/scribe/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Aug 21, 2016</span>\n",
       " <a class=\"post-link\" href=\"/2016/08/21/handwriting/\">Scribe: Generating Realistic Handwriting with TensorFlow</a>\n",
       " <br/>\n",
       "         In this post, I will demonstrate the power of deep learning by using it to generate human-like handwriting. This work is based on <em>Generating Sequences With Recurrent Neural Networks</em> by Alex Graves\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/scribe/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Aug 21, 2016</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2016/08/21/handwriting/\">Scribe: Generating Realistic Handwriting with TensorFlow</a>\n",
       "         <br>\n",
       "         In this post, I will demonstrate the power of deep learning by using it to generate human-like handwriting. This work is based on <em>Generating Sequences With Recurrent Neural Networks</em> by Alex Graves -->\n",
       " </li>, <li>\n",
       " <div style=\"display:inline-block;vertical-align:top; padding-top:20px; text-align:center;width:15%\">\n",
       " <img align=\"center\" src=\"/assets/what-is/thumbnail.png\" style=\"width:65%; height:65%\"/>\n",
       " </div>\n",
       " <div style=\"display:inline-block;width:80%\">\n",
       " <span class=\"post-date\">Aug 5, 2016</span>\n",
       " <a class=\"post-link\" href=\"/2016/08/05/what-is/\">Three Perspectives on Deep Learning</a>\n",
       " <br/>\n",
       "         After being obsessed with this field for more than a year, I should have a concise and satisfying answer. Strangely, I have three.\n",
       "         </div>\n",
       " <!--           <p>\n",
       "             \n",
       "               <img src=\"/assets/what-is/thumbnail.png\" style=\"height: 40px;\" align=\"center\" />\n",
       "             \n",
       "           </p>\n",
       "         <span class=\"post-date\">Aug 5, 2016</span> </nobr>\n",
       "         <a class=\"post-link\" href=\"/2016/08/05/what-is/\">Three Perspectives on Deep Learning</a>\n",
       "         <br>\n",
       "         After being obsessed with this field for more than a year, I should have a concise and satisfying answer. Strangely, I have three. -->\n",
       " </li>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fcvt = SamGreydanus(fetch_from_web=True)\n",
    "\n",
    "# html = fcvt.fetch_html()\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "# soup\n",
    "\n",
    "# items = fcvt.soup_items(soup)\n",
    "# items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items = [\n",
    "#     fcvt.soup_item_to_rss_item(item)\n",
    "#         for item in items    \n",
    "# ]\n",
    "\n",
    "# feed = fcvt.build_feed(items)\n",
    "# feed.rss()\n",
    "\n",
    "# (self.feeds_base / (self.name+'.xml')).write_text(feed.rss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<rss version=\"2.0\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\"><channel><title>Online and Linear-Time Attention by Enforcing Monotonic Alignments</title><link>http://colinraffel.com/blog/</link><description>Online and Linear-Time Attention by Enforcing Monotonic Alignments</description><language>en-US</language><lastBuildDate>Wed, 08 Jul 2020 21:06:44 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><image><url>https://colinraffel.com/blog/favicon.ico</url><title>icon</title><link>http://colinraffel.com/blog/</link></image><item><title>You Don't Know JAX</title><link>http://colinraffel.com/blog/you-don-t-know-jax.html</link><description>You Don't Know JAX</description><author>Colin Raffel</author><pubDate>Wed, 16 Jan 2019 00:00:00 GMT</pubDate><guid isPermaLink=\"true\">http://colinraffel.com/blog/you-don-t-know-jax.html</guid></item><item><title>Writing a Google AI Residency Cover Letter</title><link>http://colinraffel.com/blog/writing-a-google-ai-residency-cover-letter.html</link><description>Writing a Google AI Residency Cover Letter</description><author>Colin Raffel</author><pubDate>Thu, 10 Jan 2019 00:00:00 GMT</pubDate><guid isPermaLink=\"true\">http://colinraffel.com/blog/writing-a-google-ai-residency-cover-letter.html</guid></item><item><title>GANs and Divergence Minimization</title><link>http://colinraffel.com/blog/gans-and-divergence-minimization.html</link><description>GANs and Divergence Minimization</description><author>Colin Raffel</author><pubDate>Fri, 21 Dec 2018 00:00:00 GMT</pubDate><guid isPermaLink=\"true\">http://colinraffel.com/blog/gans-and-divergence-minimization.html</guid></item><item><title>Reviewing Criteria</title><link>http://colinraffel.com/blog/reviewing-criteria.html</link><description>Reviewing Criteria</description><author>Colin Raffel</author><pubDate>Mon, 26 Mar 2018 00:00:00 GMT</pubDate><guid isPermaLink=\"true\">http://colinraffel.com/blog/reviewing-criteria.html</guid></item><item><title>My Year at Brain</title><link>http://colinraffel.com/blog/my-year-at-brain.html</link><description>My Year at Brain</description><author>Colin Raffel</author><pubDate>Wed, 23 Aug 2017 00:00:00 GMT</pubDate><guid isPermaLink=\"true\">http://colinraffel.com/blog/my-year-at-brain.html</guid></item><item><title>Online and Linear-Time Attention by Enforcing Monotonic Alignments</title><link>http://colinraffel.com/blog/online-and-linear-time-attention-by-enforcing-monotonic-alignments.html</link><description>Online and Linear-Time Attention by Enforcing Monotonic Alignments</description><author>Colin Raffel</author><pubDate>Wed, 14 Jun 2017 00:00:00 GMT</pubDate><guid isPermaLink=\"true\">http://colinraffel.com/blog/online-and-linear-time-attention-by-enforcing-monotonic-alignments.html</guid></item></channel></rss>\n"
     ]
    }
   ],
   "source": [
    "# name = 'colin-raffel'\n",
    "# if name == scrap_target:\n",
    "# # if 1:\n",
    "\n",
    "#     title = 'Colin Raffel Blog'\n",
    "#     author = 'Colin Raffel'\n",
    "#     base_url = 'http://colinraffel.com/blog/'\n",
    "\n",
    "\n",
    "#     # soup = soup_from_url(base_url)\n",
    "#     soup = soup_from_file('/tmp/' + name + '.html')\n",
    "#     items = []\n",
    "\n",
    "#     for item in soup.find_all('div', class_='item'):\n",
    "#         date, post = item.find_all('div')\n",
    "#         date = date.text\n",
    "#         post = post.find('a')\n",
    "#         link = post.attrs['href']\n",
    "#         title = post.text\n",
    "#         link = urljoin(base_url, link)\n",
    "#         date = dateparser.parse(date)\n",
    "\n",
    "#         item = Item(\n",
    "#             title = title,\n",
    "#             link = link, \n",
    "#             description = title,\n",
    "#             author = author,\n",
    "#             guid = Guid(link),\n",
    "#             pubDate = date\n",
    "#         )\n",
    "\n",
    "#         items.append(item)\n",
    "        \n",
    "#     image_link = favicon.get(base_url)[0].url\n",
    "#     image = Image(image_link, 'icon', base_url)\n",
    "    \n",
    "#     feed = Feed(\n",
    "#         title = title,\n",
    "#         link = base_url,\n",
    "#         description = title,\n",
    "#         language = \"en-US\",\n",
    "#         lastBuildDate = datetime.datetime.now(),\n",
    "#         items = items,\n",
    "#         image = image\n",
    "#     )\n",
    "\n",
    "#     print(feed.rss())\n",
    "#     # (Path('feeds') / (name+'.xml')).write_text(feed.rss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# name = 'sam-greydanus'\n",
    "\n",
    "# if name == scrap_target:\n",
    "# # if 1:    \n",
    "\n",
    "#     title = 'Sam Greydanus Blog'\n",
    "#     author = 'Sam Greydanus'\n",
    "#     base_url = 'https://greydanus.github.io/'\n",
    "\n",
    "\n",
    "#     soup = soup_from_url(base_url)\n",
    "#     # print(soup)\n",
    "#     items = []\n",
    "\n",
    "#     for item in soup.find('ul', class_='posts').find_all('li'):\n",
    "        \n",
    "#         # print(item)\n",
    "#         # print('-----')\n",
    "        \n",
    "#         a = item.find('a', class_='post-link')\n",
    "                        \n",
    "#         link = a.attrs['href']        \n",
    "#         link = urljoin(base_url, link)\n",
    "        \n",
    "#         title = a.text\n",
    "        \n",
    "#         date = item.find('span',class_='post-date').text\n",
    "#         date = dateparser.parse(date)\n",
    "        \n",
    "#         description = item.text\n",
    "        \n",
    "#         # print(link, title, date, description)\n",
    "#         # print('-----')\n",
    "        \n",
    "#         item = Item(\n",
    "#             title = title,\n",
    "#             link = link, \n",
    "#             description = description,\n",
    "#             author = author,\n",
    "#             guid = Guid(link),\n",
    "#             pubDate = date,\n",
    "#             image = Image()\n",
    "#         )\n",
    "\n",
    "#         items.append(item)\n",
    "    \n",
    "    \n",
    "#     image_link = favicon.get(base_url)[0].url\n",
    "#     image = Image(image_link, 'icon', base_url)\n",
    "    \n",
    "#     feed = Feed(\n",
    "#         title = title,\n",
    "#         link = base_url,\n",
    "#         description = title,\n",
    "#         language = \"en-US\",\n",
    "#         lastBuildDate = datetime.datetime.now(),\n",
    "#         items = items)\n",
    "\n",
    "    \n",
    "#     (Path('feeds') / (name+'.xml')).write_text(feed.rss())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
